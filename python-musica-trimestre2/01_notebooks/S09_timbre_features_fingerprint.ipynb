{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S09 ‚Äî Timbre, enerx√≠a e ‚Äúpegada sonora‚Äù (features + comparaci√≥n)\n",
    "**Curso:** Programaci√≥n Musical con Python ‚Äî 2¬∫ Trimestre  \n",
    "**Duraci√≥n:** 1 sesi√≥n (‚âà 1 hora)\n",
    "\n",
    "## üéØ Obxectivos\n",
    "- Entender ‚Äúfeatures‚Äù sinxelas de audio: **enerx√≠a** e **timbre**.\n",
    "- Calcular e visualizar:\n",
    "  - RMS (enerx√≠a)\n",
    "  - Centroide espectral (brillo)\n",
    "  - Zero Crossing Rate (rugosidade/ru√≠do)\n",
    "- Constru√≠r unha **pegada sonora** (vector de features) para comparar audios.\n",
    "- Mini-clasificaci√≥n simple: decidir cal fragmento √© A/B con regras.\n",
    "\n",
    "> üéõÔ∏è Hoxe facemos MIR suave: datos do son, sen IA complexa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Setup (Colab)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip -q install librosa soundfile\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "print(\"‚úÖ librosa listo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Cargar audio(s)\n",
    "\n",
    "Usaremos 2 audios de exemplo de librosa para comparar.\n",
    "Tam√©n podes usar 1 audio e cortar 2 fragmentos (como no S08).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "path1 = librosa.ex(\"trumpet\")\n",
    "path2 = librosa.ex(\"choice\")\n",
    "\n",
    "y1, sr1 = librosa.load(path1, sr=None)\n",
    "y2, sr2 = librosa.load(path2, sr=None)\n",
    "\n",
    "print(\"Audio1 sr/dur:\", sr1, round(len(y1)/sr1, 2), \"s\")\n",
    "print(\"Audio2 sr/dur:\", sr2, round(len(y2)/sr2, 2), \"s\")\n",
    "\n",
    "display(Audio(y1, rate=sr1))\n",
    "display(Audio(y2, rate=sr2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Features b√°sicas (a nosa ‚Äúcaixa de ferramentas‚Äù)\n",
    "\n",
    "### RMS (Root Mean Square) = enerx√≠a\n",
    "- canto m√°is alto, m√°is ‚Äúforte‚Äù (en media)\n",
    "\n",
    "### Centroide espectral = brillo\n",
    "- canto m√°is alto, m√°is ‚Äúbrillante‚Äù / m√°is agudos dominantes\n",
    "\n",
    "### Zero Crossing Rate (ZCR)\n",
    "- cantos cruces por cero: m√°is alto ‚Üí m√°is ru√≠do / textura √°spera\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def features_basicas(y, sr):\n",
    "    rms = librosa.feature.rms(y=y)[0]\n",
    "    centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
    "    return rms, centroid, zcr\n",
    "\n",
    "rms1, cent1, zcr1 = features_basicas(y1, sr1)\n",
    "rms2, cent2, zcr2 = features_basicas(y2, sr2)\n",
    "\n",
    "print(\"Feature lengths:\", len(rms1), len(cent1), len(zcr1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Visualizar features no tempo\n",
    "\n",
    "Debuxamos cada feature como unha curva ao longo do tempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_feature(feat, sr, hop_length=512, title=\"\"):\n",
    "    times = librosa.frames_to_time(np.arange(len(feat)), sr=sr, hop_length=hop_length)\n",
    "    plt.figure()\n",
    "    plt.plot(times, feat)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Tempo (s)\")\n",
    "    plt.show()\n",
    "\n",
    "plot_feature(rms1, sr1, title=\"RMS (enerx√≠a) - audio1\")\n",
    "plot_feature(cent1, sr1, title=\"Centroide espectral (brillo) - audio1\")\n",
    "plot_feature(zcr1, sr1, title=\"ZCR - audio1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_feature(rms2, sr2, title=\"RMS (enerx√≠a) - audio2\")\n",
    "plot_feature(cent2, sr2, title=\"Centroide espectral (brillo) - audio2\")\n",
    "plot_feature(zcr2, sr2, title=\"ZCR - audio2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) ‚ÄúPegada sonora‚Äù (fingerprint) simple\n",
    "\n",
    "Imos resumir cada audio cun vector de 6 n√∫meros:\n",
    "- media e desviaci√≥n t√≠pica de RMS\n",
    "- media e desviaci√≥n t√≠pica de centroide\n",
    "- media e desviaci√≥n t√≠pica de ZCR\n",
    "\n",
    "Isto √© unha pegada num√©rica para comparar.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fingerprint(y, sr):\n",
    "    rms, cent, zcr = features_basicas(y, sr)\n",
    "    vec = np.array([\n",
    "        np.mean(rms),  np.std(rms),\n",
    "        np.mean(cent), np.std(cent),\n",
    "        np.mean(zcr),  np.std(zcr)\n",
    "    ], dtype=float)\n",
    "    return vec\n",
    "\n",
    "fp1 = fingerprint(y1, sr1)\n",
    "fp2 = fingerprint(y2, sr2)\n",
    "\n",
    "fp1, fp2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaci√≥n por distancia\n",
    "\n",
    "Se dous audios te√±en pegadas parecidas, a distancia ser√° pequena.\n",
    "Usaremos distancia eucl√≠dea (sinxela).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dist(a, b):\n",
    "    return float(np.linalg.norm(a - b))\n",
    "\n",
    "print(\"Distancia fp1‚Äìfp2:\", round(dist(fp1, fp2), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Mini-clasificador por regras (sen IA)\n",
    "\n",
    "Exemplo de regra:\n",
    "- Se o centroide medio √© alto ‚Üí m√°is brillante\n",
    "- Se o ZCR medio √© alto ‚Üí m√°is ru√≠doso\n",
    "\n",
    "Imos facer unha funci√≥n que ‚Äúdescribe‚Äù un audio.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def describir(fp):\n",
    "    rms_m, rms_s, cent_m, cent_s, zcr_m, zcr_s = fp\n",
    "    desc = []\n",
    "    desc.append(\"m√°is forte\" if rms_m > 0.05 else \"m√°is suave\")\n",
    "    desc.append(\"m√°is brillante\" if cent_m > 2000 else \"m√°is escuro\")\n",
    "    desc.append(\"m√°is ru√≠doso\" if zcr_m > 0.08 else \"m√°is limpo\")\n",
    "    return \", \".join(desc)\n",
    "\n",
    "print(\"Audio1:\", describir(fp1))\n",
    "print(\"Audio2:\", describir(fp2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Clasificaci√≥n simple de fragmentos (exercicio)\n",
    "\n",
    "Imos cortar 2 fragmentos do mesmo audio e ver se podemos diferencialos.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cortar(y, sr, inicio_s, fin_s):\n",
    "    i0 = int(inicio_s * sr)\n",
    "    i1 = int(fin_s * sr)\n",
    "    return y[i0:i1]\n",
    "\n",
    "# Cortes do audio2 (r√≠tmico)\n",
    "fragA = cortar(y2, sr2, 0, 6)\n",
    "fragB = cortar(y2, sr2, 6, 12)\n",
    "\n",
    "display(Audio(fragA, rate=sr2))\n",
    "display(Audio(fragB, rate=sr2))\n",
    "\n",
    "fpA = fingerprint(fragA, sr2)\n",
    "fpB = fingerprint(fragB, sr2)\n",
    "\n",
    "print(\"FragA:\", describir(fpA))\n",
    "print(\"FragB:\", describir(fpB))\n",
    "print(\"Distancia A‚ÄìB:\", round(dist(fpA, fpB), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© Mini-proxecto avaliable (entrega)\n",
    "\n",
    "### Parte A (t√©cnica)\n",
    "Escolle 2 opci√≥ns:\n",
    "\n",
    "**Opci√≥n 1 (dous audios distintos)**\n",
    "- Comparar 2 audios (ex. trompeta vs ritmo)\n",
    "- Calcular RMS, centroide, ZCR\n",
    "- Constru√≠r fingerprint e distancia\n",
    "\n",
    "**Opci√≥n 2 (dous fragmentos do mesmo audio)**\n",
    "- Cortar 2 fragmentos diferentes\n",
    "- Calcular features e fingerprint\n",
    "- Comparar por distancia e por descrici√≥n\n",
    "\n",
    "### Parte B (reflexi√≥n, 8‚Äì10 li√±as)\n",
    "- Que feature che axudou m√°is a diferenciar?\n",
    "- Coincide co que escoitas?\n",
    "- Que limitaci√≥ns ten esta aproximaci√≥n (sen IA)?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ‚úÖ Espazo de traballo: escolle a t√∫a opci√≥n aqu√≠\n",
    "\n",
    "# Opci√≥n 1: carga dous audios teus (subidos) e chama fingerprint()\n",
    "# ruta1 = \"audio1.wav\"\n",
    "# ruta2 = \"audio2.wav\"\n",
    "\n",
    "# Opci√≥n 2: usa un audio e corta dous fragmentos diferentes\n",
    "# y, sr = librosa.load(ruta1, sr=None)\n",
    "# frag1 = cortar(y, sr, 0, 5)\n",
    "# frag2 = cortar(y, sr, 5, 10)\n",
    "# fp1 = fingerprint(frag1, sr)\n",
    "# fp2 = fingerprint(frag2, sr)\n",
    "# print(dist(fp1, fp2), describir(fp1), describir(fp2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Ler c√≥digo como partitura (checkpoint)\n",
    "Antes de entregar:\n",
    "- `# CARGA`\n",
    "- `# FEATURES`\n",
    "- `# FINGERPRINT`\n",
    "- `# COMPARACI√ìN`\n",
    "- `# INTERPRETACI√ìN`\n",
    "O notebook debe lerse como un ‚Äúinforme musical‚Äù estruturado.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "S09_timbre_features_fingerprint.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}